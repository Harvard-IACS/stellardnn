<!DOCTYPE html>
<html lang="en">

<head>
    <!-- Title -->
    <title>StellarDNN projects | Project Descriptions</title>

    <!-- Required Meta Tags Always Come First -->
    <meta charset="utf-8">
    <meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport">

    <!-- Favicon -->
    <link href="./favicon.ico" rel="shortcut icon">

    <!-- Font -->
    <link href="https://fonts.googleapis.com/css2?family=Open+Sans:wght@400;600&display=swap" rel="stylesheet">

    <!-- CSS Implementing Plugins -->
    <link href="assets/front_v3_3/vendor/fontawesome/css/all.min.css" rel="stylesheet">
    <link href="assets/front_v3_3/vendor/hs-mega-menu/dist/hs-mega-menu.min.css" rel="stylesheet">

    <!-- CSS Front Template -->
    <link href="assets/front_v3_3/css/theme.min.css" rel="stylesheet">

</head>

<body>
    <!-- ========== HEADER ========== -->
    <header-component></header-component>
    <!-- ========== END HEADER ========== -->

    <!-- ========== MAIN ========== -->
    <main id="content " role="main ">
        <!-- User Profile Section -->
       
        <div class="container space-top-3 space-bottom-2 ">
            <div class="border-bottom w-md-75 w-lg-60 space-bottom-2 mx-md-auto ">
              
                <div class="media d-block d-sm-flex ">
                    
                   
                    <div class="media-body ">
                        
                        <div class="d-flex justify-content-between align-items-center mb-2 ">
                           <br><br><br>
                            
                        </div>
                        
                   
                    </div>
                    
              
                </div>
                <h1 class="h3 ">  Project descriptions</h1>
                            
                        

                <p class="mb-0 "> On this page, you'll discover projects that are still in progress and for which we are actively 
                    seeking students or collaborators to contribute.        </div>
        </div>
        <!-- End User Profile Section -->

        <!-- Blog Listing Section -->
        <div class="container space-bottom-3">
            <div class="w-md-75 w-lg-60 mx-md-auto ">
                <!-- End Blog Card -->
                <article class="card mb-3 mb-sm-5" id="NeuroDiffHUB">
                    <img style="width:100pt" alt="Image Descriptions" class="card-img-top " src="assets/general/img/home/neurodiffhub_logo.png">
                    <div class="card-body ">
                        <a class="d-block small font-weight-bold text-cap mb-2" href="http://dev.neurodiff.io">NeuroDiffHUB</a>

                        <h2 class="h3 "> What is NeuroDiffHub</h2>

                        <p>Neurodiffhub is a platform that uses neural networks to store and 
                            disseminate solutions to differential equations. 
                            It includes a web application that allows users to search for specific differential equation, 
                            and an API that can be used  to load and save solutions.
                            The platform aims to provide a central repository for 
                            solutions to differential equations and make it easier for researchers 
                            and practitioners to access and use these solutions in their work. 
                         </p>

                         
                    </div>
                </article>
                <!-- End Blog Card -->

                <!-- End Blog Card -->
                <article class="card mb-3 mb-sm-5 " id="NeuroDiffEq">
                    <img style="width:100pt" alt="Image Description " class="card-img-top " src="assets/general/img/home/diffeq_logo.png">

                    <div class="card-body ">
                        <a class="d-block small font-weight-bold text-cap mb-2 " href="projects/neurodiff.html">NeuroDiffEq</a>

                        <h3>Solving Differential Equations Using Neural Networks</h3>

                        <p> Differential equations occur in various scientific and 
                            engineering domains. Most differential equations of practical 
                            interest are analytically intractable. 
                            Traditionally, differential equations are solved by numerical methods. 
                            Neural networks have been proven to be universal function approximators, 
                            suggesting the possibility of using ANNs to solve differential equations. 
                            These approaches are knows as Physics Informed Neural Networks (PINNs) 
                            have been one of the focus of our work. 
                            Those include NN solutions that preserve physical symmetries or symmetries in general, 
                            specialize networks for Hamiltonian systems, using GANs architectures to enhance the 
                            performance, a library that allows researchers to deploy these solutions. 
                            In this page you will find a summary of all current and future work. 
                            
                           
                    </div>
                </article>
                <!-- End Blog Card -->

                <!-- End Blog Card -->
                <article class="card mb-3 mb-sm-5" id="Astromer">
                    <img style="width:100pt" alt="Image Description " class="card-img-top "  src="assets/general/img/home/logo_astromer.png ">
                    <div class="card-body ">
                        <a class="d-block small font-weight-bold text-cap mb-2" href="https://www.stellardnn.org/projects/astromer/index.html">Astromer</a>

                        <h2 class="h3 ">Spectromer</h2>

                        <p> Foundational Model for Spectra
                            <p> Foundational Model for Spectra

                                Spectroscopic data are crucial for astronomical research. Observing celestial objects across various wavelengths reveals more information about them than most other observational techniques. Spectra typically represent the intensity of light at various wavelengths or wavelength bins. A typical spectrum can range from a few hundred to several thousand observations. As data, a spectrum is a sequence of light intensities at the center of each wavelength bin. [ADD wavelenth ranges]
                                
                                A typical celestial object will exhibit a blackbody radiation spectrum following the Stefan-Boltzmann law [1], which depends on the object's temperature, along with a series of absorption and emission lines. Together, these features provide insights into the object's temperature, mass, age, and elemental abundances [2]. Moreover, these spectral lines are shifted according to the object's proper motion, enabling the deduction of intrinsic velocities and cosmological properties [3].
                                
                                Due to the significance of spectroscopic data, astronomers have developed sophisticated instruments for spectral observations. In particular, observing the spectra of numerous celestial objects has motivated outstanding engineering achievements. Currently, millions of spectra are available through various surveys, such as the Sloan Digital Sky Survey (SDSS) [4] and the Gaia mission [5].
                                
                                Spectra have been extensively used in the analysis and classification of celestial objects. Stars are classified according to their spectral features using the Harvard Classification system [6], and objects can be assigned to variability types and classified into categories like stars, galaxies, and active galactic nuclei (AGNs) based on their spectra [7].
                                
                                In this project, we aim to create a foundational model using transformers for embeddings of various types of spectra. We will leverage millions of available spectra to pre-train the model following the paradigms of masked language models (though adapted for continuous data) and next-sentence predictions. We will then test the embeddings by fine-tuning and using either regression or classification tasks.  The project will take advantage of our previous work on time series analysis and adapt it to spectroscopic data, as described in the astromer paper by Donoso et al. [8]. The final models will be made available as pre-trained models for the community to use. Additionally, we will adhere to proper ML-OPS standards, utilizing cloud infrastructure for training and deployment, as well as data and code versioning practices.
                                
                                References: [1] Stefan-Boltzmann law: [https://en.wikipedia.org/wiki/Stefan%E2%80%93Boltzmann_law](https://en.wikipedia.org/wiki/Stefanâ€“Boltzmann_law) 
                                
                                [2] Spectroscopic analysis of stellar properties: https://www.annualreviews.org/doi/10.1146/annurev-astro-081817-051846 
                                
                                [3] Doppler shift and spectral line analysis: https://astronomy.swin.edu.au/cosmos/D/Doppler+Shift 
                                
                                [4] Sloan Digital Sky Survey (SDSS): https://www.sdss.org/ 
                                
                                [5] Gaia mission: https://www.cosmos.esa.int/web/gaia 
                                
                                [6] Harvard Classification system: https://en.wikipedia.org/wiki/Stellar_classification 
                                
                                [7] Spectroscopic classification of celestial objects: https://iopscience.iop.org/article/10.3847/1538-4357/aa6890
                                
                                [8] Donoso et al. - astromer: </p>
                    </div>
                </article>
                <!-- End Blog Card -->

                <!-- Start Blog Card -->
                <article class="card mb-3 mb-sm-5 " id="NNEHT" onclick = "window.location.href='projects/nneht.html'" style="cursor:pointer">
                    <img style="width:100pt"  alt="Image Description " class="card-img-top " src="assets/general/img/home/NNEHT_logo.svg">

                    <div class="card-body " style="cursor:pointer">
                        <a class="d-block small font-weight-bold text-cap mb-2 " href="projects.html#NNETH">NNETH</a>

                        <h3>Computer Vision methods for the Event Horizon Telescope</h3>

                        <p> In 2019, the Event Horizon Telescope Collaboration released the first-ever 
                            image of the M87* 
                            supermassive black hole. Accurate parameterization of images like this 
                            can provide new information 
                            regarding the dynamics of matter close to a black hole. 
                            Moreover, it can enable us to test theories of gravity 
                            and deepen our understanding of the magnetized relativistic 
                            jets created by the blackhole. 
                            In these projects, we deploy deep learning, to parameterize and estimate the 
                            physical parameters of M87*.   </p>

                         
                    </div>
                </article>
                <!-- End Blog Card -->


                <!-- End Blog Card -->
                <article class="card mb-3 mb-sm-5 " id="RCTorch">
                    <img style="width:100pt"  alt="Image Description " class="card-img-top " src="assets/general/img/home/RCTORCH_logo.png">

                    <div class="card-body ">
                        <a class="d-block small font-weight-bold text-cap mb-2 " href="projects.html#RCTorch">RCTorch</a>

                        <h3>Reservoid Computing</h3>

                        <p>Reservoir computers (RCs) are among the fastest to train of all neural networks, 
                            especially when compared to other recurrent neural networks. 
                            RC has this advantage while still handling sequential data exceptionally well. 
                            However, RC adoption has lagged other neural network models because of the model's 
                            sensitivity to its hyper-parameters (HPs).
                            We developed \rctorch, a \pytorch based RC neural network package with automated HP tuning. 
                            In addition, we introduce an unsupervised reservoir computing (RC), capable of discovering 
                            approximate solutions that satisfy ordinary differential equations (ODEs). 
                    </div>
                </article>
                <!-- End Blog Card -->


                <!-- End Blog Card -->
                <article class="card mb-3 mb-sm-5" id="Cosmology">
                    <img style="width:100pt"  alt="Image Description " class="card-img-top " src="assets/general/img/home/COSMO_logo.png">
                    <div class="card-body ">
                        <a class="d-block small font-weight-bold text-cap mb-2" href="projects.html#Cosmology">CINNs</a>

                        <h2 class="h3 ">Cosmologically Informed NNs </h2>

                        <p>The field of machine learning has drawn increasing interest from various fields due to its methods' 
                            success in solving many different problems. An application of these has been to train artificial neural 
                            networks to solve differential equations without needing a numerical solver. In these works, we use 
                            artificial neural networks to represent solutions of the differential equations that govern the 
                            background dynamics of the Universe for four different models. We have applied these methods to various models such as the  &Lambda;CDM, a quintessence model with exponential potential, and the Hu-Sawicki f(R) model. 
                            We used the networks' solutions to perform statistical analyses to estimate the values of 
                            each model's parameters with observational data. Additionally, we use similar methods for holographic 
                            calculation of the bubble wall velocity in a cosmological phase transition, which is crucial to determine 
                            the resulting spectrum of GWs. </p>

                        
                    </div>
                </article>
                <!-- End Blog Card -->

                <!-- End Blog Card -->
                <article class="card mb-3 mb-sm-5" id="ADSML">
                    <img style="width:100pt"  alt="Image Description " class="card-img-top " src="assets/general/img/home/ADSML_logo.png">
                    <div class="card-body ">
                        <a class="d-block small font-weight-bold text-cap mb-2" href="projects.html#ADSML">ADSML</a>

                        <h2 class="h3 ">ADSML</h2>

                        <p>he SAO/NASA Astrophysics Data System (ADS) is a digital library portal for researchers in astronomy and physics, 
                            operated by the Smithsonian Astrophysical Observatory (SAO) under a NASA grant.
                             ADS maintains three bibliographic collections containing more than 15 million records covering 
                             publications in astronomy and astrophysics, physics, and general science, including all arXiv e-prints. 
                             The abstracts and full text of major astronomy and physics publications are indexed and searchable. 
                             At ADS ML, we are applying modern machine learning and natural language processing techniques to 
                             the ADS dataset to train astroBERT, a deeply contextual language model based on research at Google.
                              Using astroBERT, we aim to enrich the ADS dataset and improve its discoverability; in particular, 
                              we are developing our own named entity recognition and concept discovery tools.</p>

                         
                    </div>
                </article>
                <!-- End Blog Card -->

                <!-- End Blog Card -->
                <article class="card mb-3 mb-sm-5 " id="Other">
                    <img style="width:100pt"  alt="Image Description " class="card-img-top " src="assets/general/img/home/OTHER_logo.png">

                    <div class="card-body ">
                        <a class="d-block small font-weight-bold text-cap mb-2 " href="projects.html#Other">Other</a>

                        <h3>Other projects</h3>

                        <p> Besides the projects described above, we have engaged in various other projects in particularly in astronomy and physics. 
                            Work on StellarNet , eigenvalue problems, embedding on galaxy images using auto-encoders and other topics are described 
                            in the page link provided. </p>

                        
                    </div>
                </article>
                <!-- End Blog Card -->


                <div class="space-bottom-2"></div>

            </div>
        </div>
        <!-- End Blog Listing Section -->
    </main>
    <!-- ========== END MAIN ========== -->

    <!-- ========== FOOTER ========== -->
    <footer-component></footer-component>
    <!-- ========== END FOOTER ========== -->


    <!-- JS Global Compulsory  -->
    <script src="assets/front_v3_3/vendor/jquery/dist/jquery.min.js "></script>
    <script src="assets/front_v3_3/vendor/jquery-migrate/dist/jquery-migrate.min.js"></script>
    <script src="assets/front_v3_3/vendor/bootstrap/dist/js/bootstrap.bundle.min.js "></script>

    <!-- JS Implementing Plugins -->
    <script src="assets/front_v3_3/vendor/hs-header/dist/hs-header.min.js"></script>
    <script src="assets/front_v3_3/vendor/hs-go-to/dist/hs-go-to.min.js "></script>
    <script src="assets/front_v3_3/vendor/hs-unfold/dist/hs-unfold.min.js"></script>
    <script src="assets/front_v3_3/vendor/hs-mega-menu/dist/hs-mega-menu.min.js "></script>
    <script src="assets/front_v3_3/vendor/hs-show-animation/dist/hs-show-animation.min.js"></script>
    <script src="assets/front_v3_3/vendor/jquery-validation/dist/jquery.validate.min.js "></script>

    <!-- JS Front -->
    <script src="assets/front_v3_3/js/theme.min.js"></script>

    <!-- IE Support -->
    <script>
        if (/MSIE \d|Trident.*rv:/.test(navigator.userAgent)) document.write('<script src="assets/front_v3_3/vendor/babel-polyfill/dist/polyfill.js"><\/script>');
    </script>

    <!-- JS -->
    <script src="assets/common_components/js/header.js"></script>
    <script src="assets/common_components/js/footer.js"></script>
</body>

</html>