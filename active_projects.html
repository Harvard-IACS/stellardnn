<!DOCTYPE html>
<html lang="en">

<head>
    <!-- Title -->
    <title>StellarDNN projects | Project Descriptions</title>

    <!-- Required Meta Tags Always Come First -->
    <meta charset="utf-8">
    <meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport">

    <!-- Favicon -->
    <link href="./favicon.ico" rel="shortcut icon">

    <!-- Font -->
    <link href="https://fonts.googleapis.com/css2?family=Open+Sans:wght@400;600&display=swap" rel="stylesheet">

    <!-- CSS Implementing Plugins -->
    <link href="assets/front_v3_3/vendor/fontawesome/css/all.min.css" rel="stylesheet">
    <link href="assets/front_v3_3/vendor/hs-mega-menu/dist/hs-mega-menu.min.css" rel="stylesheet">

    <!-- CSS Front Template -->
    <link href="assets/front_v3_3/css/theme.min.css" rel="stylesheet">

</head>

<body>
    <!-- ========== HEADER ========== -->
    <header-component></header-component>
    <!-- ========== END HEADER ========== -->

    <!-- ========== MAIN ========== -->
    <main id="content " role="main ">
        <!-- User Profile Section -->
       
        <div class="container space-top-3 space-bottom-2 ">
            <div class="border-bottom w-md-75 w-lg-60 space-bottom-2 mx-md-auto ">
              
                <div class="media d-block d-sm-flex ">
                    
                   
                    <div class="media-body ">
                        
                        <div class="d-flex justify-content-between align-items-center mb-2 ">
                           <br><br><br>
                            
                        </div>
                        
                   
                    </div>
                    
              
                </div>
                <h1 class="h3 ">  Project descriptions</h1>
                            
                        

                <p class="mb-0 "> On this page, you'll discover projects that are still in progress and for which we are actively 
                    seeking students or collaborators to contribute.        </div>
        </div>
        <!-- End User Profile Section -->

        <!-- Blog Listing Section -->
        <div class="container space-bottom-3">
            <div class="w-md-75 w-lg-60 mx-md-auto ">
                <!-- End Blog Card -->
                <article class="card mb-3 mb-sm-5" id="NeuroDiffHUB">
                    <img style="width:100pt" alt="Image Descriptions" class="card-img-top " src="assets/general/img/home/neurodiffhub_logo.png">
                    <div class="card-body ">
                        <a class="d-block small font-weight-bold text-cap mb-2" href="http://dev.neurodiff.io">NeuroDiffHUB</a>

                        <h2 class="h3 "> What is NeuroDiffHub</h2>

                        <p>Neurodiffhub is a platform that uses neural networks to store and 
                            disseminate solutions to differential equations. 
                            It includes a web application that allows users to search for specific differential equation, 
                            and an API that can be used  to load and save solutions.
                            The platform aims to provide a central repository for 
                            solutions to differential equations and make it easier for researchers 
                            and practitioners to access and use these solutions in their work. 
                         </p>

                         
                    </div>
                </article>
                <!-- End Blog Card -->

                <!-- End Blog Card -->
                <article class="card mb-3 mb-sm-5 " id="NeuroDiffEq">
                    <img style="width:100pt" alt="Image Description " class="card-img-top " src="assets/general/img/home/diffeq_logo.png">

                    <div class="card-body ">
                        <a class="d-block small font-weight-bold text-cap mb-2 " href="projects/neurodiff.html">NeuroDiffEq</a>

                        <h3 id='one-shot-transfer-learning-for-nonlinear-differential-equations-with-neural-networks'>One-Shot Transfer Learning for Nonlinear Differential Equations with Neural Networks</h2>
                    <p>The ability to rapidly adapt neural networks for solving various differential equations holds immense potential. Achieving &quot;one-shot transfer learning&quot; would pave the way for foundational models applicable to entire families of differential equations, encompassing both ordinary (ODEs) and partial differential equations (PDEs). Such models could efficiently handle diverse initial conditions, forcing functions, and other parameters, offering a universally reusable solution framework.</p>
                    <p><strong>Background and Prior Work:</strong></p>
                    <p>Our research has made significant strides in this direction. We previously demonstrated one-shot transfer learning for linear equations [1,2]. Subsequently, we built upon this success by employing perturbation methods to achieve iterative one-shot transfer learning for simple polynomial nonlinearities in differential equations [3].</p>
                    <p><strong>Project Goals:</strong></p>
                    <p>This project aims to extend our prior work by tackling non-polynomial nonlinearities in differential equations. While our prior work utilized the homotopy perturbation method, its limited convergence regions pose a challenge. Here, we propose exploring alternative expansion techniques, such as Pade approximations [3], as a means to effectively handle a broader range of nonlinearities.</p>
                    <p><strong>Methodology:</strong></p>
                    <ol>
                    <li><strong>Exploration of Expansion Techniques:</strong> We will delve into Pade approximations and potentially other expansion methods suitable for representing diverse nonlinearities in differential equations.</li>
                    <li><strong>Model Development:</strong> We will integrate the chosen expansion technique into a neural network architecture, enabling the model to learn the solution structure for various non-polynomial nonlinearities.</li>
                    <li><strong>Benchmarking and Validation:</strong> The model&#39;s performance will be evaluated across a diverse set of ODEs and PDEs.</li>
                    <li><strong>Real-World Application:</strong> We will select a specific real-world application involving non-polynomial nonlinearities and demonstrate the effectiveness of the developed model in solving the corresponding differential equations.</li>

                    </ol>
                    <p><strong>References:</strong></p>
                    <ol>
                    <li><p><a href='https://arxiv.org/abs/2110.11286'>One-shot transfer learning of physics-informed neural networks</a></p>
                    </li>
                    <li><p> <a href='https://openreview.net/forum?id=x2Mscu1b7H'>Generalized One-Shot Transfer Learning of Linear Ordinary and Partial Differential Equations</a></p>
                    </li>
                    <li><p><a href='https://arxiv.org/abs/2311.14931'>One-Shot Transfer Learning for Nonlinear ODEs</a></p>
                    </li>
                    <li><a href='https://www.sciencedirect.com/science/article/pii/S0377042799000424'>Algebraic <strong>approximants</strong> and the numerical solution of parabolic equations</a></h3>
                    </li>

                    </ol>
<p>&nbsp;</p>
                           
                    </div>
                </article>
                <!-- End Blog Card -->

                <!-- End Blog Card -->
                <article class="card mb-3 mb-sm-5" id="Astromer">
                    <img style="width:100pt" alt="Image Description " class="card-img-top "  src="assets/general/img/home/logo_astromer.png ">
                    <div class="card-body ">
                        <a class="d-block small font-weight-bold text-cap mb-2" href="https://www.stellardnn.org/projects/astromer/index.html">Astromer</a>

                        <h2 class="h3 ">Spectromer</h2>

                        <p> Foundational Model for Spectra
                            <p> Foundational Model for Spectra
                                Spectroscopic data are crucial for astronomical research. Observing celestial objects across various wavelengths 
                                reveals more information about them than most other observational techniques. Spectra typically represent the intensity of 
                                light at various wavelengths or wavelength bins. A typical spectrum can range from a few hundred to several thousand observations. 
                                As data, a spectrum is a sequence of light intensities at the center of each wavelength bin, which typically ranges from 400 to 1000 nm.
                                <br/> <br/>
                                Typical stellar spectra will exhibit a blackbody radiation spectrum following the Stefan-Boltzmann law [1], which depends on the object's temperature, 
                                along with a series of absorption and emission lines. Similarly other celestial objects have unique characteristics. 
                                These features provide insights into the object's temperature, mass, age, and elemental abundances [2]. Moreover, these spectra
                                lines are shifted according to the object's proper motion, enabling the deduction of intrinsic velocities and cosmological properties [3].
                                <br/> <br/>
                                Spectra are orders of magnitude more scarce than traditional imaging, as it require longer exposure times and more delicate equipment. 
                                Due to the significance of spectroscopic data, astronomers have developed sophisticated instruments for spectral observations. 
                                In particular, observing the spectra of numerous celestial objects has motivated outstanding engineering achievements. 
                                Currently, millions of spectra are available through various surveys, such as the Sloan Digital Sky Survey (SDSS) [4] and the Gaia mission [5].
                                <br/> <br/>
                                Spectra have been extensively used in the analysis and classification of celestial objects. Stars are classified 
                                according to their spectral features using the Harvard Classification system [6], and objects can be assigned to variability 
                                types and classified into categories like stars, galaxies, and active galactic nuclei (AGNs) based on their spectra [7].
                                <br/> <br/>
                                In this project, we aim to create a foundational model using transformers for embeddings of various types of spectra. 
                                We will leverage millions of available spectra to pre-train the model following the paradigms of masked 
                                language models (though adapted for continuous data) and next-sentence predictions. We will then test the embeddings 
                                by fine-tuning and using either regression or classification tasks.  The project will take advantage of our previous work 
                                on time series analysis and adapt it to spectroscopic data, as described in the Astromer paper by Donoso et al. [8]. 
                                The final models will be made available as pre-trained models for the community to use. 
                                Additionally, we will adhere to proper software development and ML-OPS standards, utilizing cloud infrastructure 
                                for training and deployment, as well as data and code versioning practices.
                                <br/> <br/><br/> <br/>

                                References: 
                                <br/> <br/>
                                [1] Stefan-Boltzmann law: 
                                <a href="https://en.wikipedia.org/wiki/Stefan–Boltzmann_law">https://en.wikipedia.org/wiki/Stefan–Boltzmann_law</a>
                                <br/> <br/>
                                [2] Spectroscopic analysis of stellar properties: 
                                <a href="https://www.annualreviews.org/doi/10.1146/annurev-astro-081817-051846">https://www.annualreviews.org/doi/10.1146/annurev-astro-081817-051846</a> 
                                <br/> <br/>
                                [3] Doppler shift and spectral line analysis: 
                                <a href="https://astronomy.swin.edu.au/cosmos/D/Doppler+Shift">https://astronomy.swin.edu.au/cosmos/D/Doppler+Shift </a> 
                                <br/> <br/>
                                [4] Sloan Digital Sky Survey (SDSS): 
                                <a href="https://www.sdss.org/"> https://www.sdss.org/</a>
                                <br/> <br/>
                                [5] Gaia mission: 
                                <a href="https://www.cosmos.esa.int/web/gaia">https://www.cosmos.esa.int/web/gaia </a>
                                <br/> <br/>
                                [6] Harvard Classification system:
                                <a href="https://en.wikipedia.org/wiki/Stellar_classification"> https://en.wikipedia.org/wiki/Stellar_classification </a>
                                <br/> <br/>
                                [7] Spectroscopic classification of celestial objects:
                                <a href="https://iopscience.iop.org/article/10.3847/1538-4357/aa6890"> https://iopscience.iop.org/article/10.3847/1538-4357/aa6890</a>
                                <br/> <br/>
                                [8] ASTROMER-A transformer-based embedding for the representation of light curves. Astronomy & Astrophysics 
                                <a href="https://www.aanda.org/articles/aa/pdf/2023/02/aa43928-22.pdf">https://www.aanda.org/articles/aa/pdf/2023/02/aa43928-22.pdf</a>

                                 </p>
                    </div>


                    <div class="card-body ">
                        

                        <h2 class="h3 ">Multi-Band Astromer</h2>
                    <p>Multi-Band Astromer; Modeling Multi-band Lightcurves for Astronomical Surveys</p>
                    <p>Astronomical surveys rely on collecting data across various wavelengths, known as bands. Each band captures light at a specific range within the electromagnetic spectrum. This multi-band approach provides rich information about celestial objects, enabling astronomers to infer properties like temperature, composition, and age.</p>
                    <p>Building robust models for astronomical lightcurves, which represent brightness variations over time, presents a unique challenge when dealing with multi-band data. A straightforward method, inspired by Astromer [1], involves feeding multi-band observations directly into a transformer-based encoder as a multi-dimensional input. However, telescopes often employ different physical filters for observations bands, leading to inconsistencies in data acquisition times. Traditional transformer architectures struggle with such asynchronous data.</p>
                    <p>This project aims to explore alternative approaches for effectively handling multi-band lightcurve data. We will investigate methods beyond the basic multi-dimensional input approach:</p>
                    <ul>
                    <li>Late Fusion with Embedding Mixing: Here, we will train independent transformer encoders for each band, similar to Astromer. However, instead of feeding the combined bands directly, we will extract embeddings from each individual encoder. These embeddings will then be combined using techniques like embedding mixing [2] only when addressing the final task (e.g., classification, regression). This approach allows for independent processing of asynchronous data while leveraging the power of transformers.</li>
                    <li>Multi-attention Layers: We will go into more complex architectures, specifically exploring the use of multi-attention layers within the transformer framework. These layers enable the model to attend to information across different bands at various time steps, potentially capturing the relationships between asynchronous observations.</li>

                    </ul>
                    <p><strong>Flexible Input Pipeline and Model Applications:</strong></p>
                    <p>To ensure maximum adaptability, we will develop a flexible input pipeline capable of ingesting data from various multi-band astronomical sources. This pipeline will preprocess and format the data seamlessly, regardless of the specific survey or telescope behind the observations.</p>
                    <p>Once the models are trained, we can fine-tune them using rich public datasets like Gaia DR3 (third data release of the Gaia space mission) and ZTF DR20 (the Zwicky Transient Facility DR20). These datasets provide a wealth of multi-band lightcurve information for a multitude of celestial objects.</p>
                    <p>The fine-tuned models can then be employed for various astronomical tasks, including:</p>
                    <ul>
                    <li><strong>Classification of Variable Objects:</strong> By analyzing lightcurve patterns, the models can identify objects whose brightness fluctuates over time, such as pulsating stars or eclipsing binary systems.</li>
                    <li><strong>Prediction of Physical Parameters:</strong> The models can be trained to predict the physical properties of objects based on their lightcurve characteristics. This could involve estimating an object&#39;s temperature, mass, or even its distance through techniques like redshift estimation.</li>

                    </ul>
                    <p>As we will go deeper into this project, potential areas for future exploration include:</p>
                    <ul>
                    <li>Integrating additional data sources, such as spectroscopic information, to enhance model performance.</li>
                    <li>Investigating the effectiveness of self-attention mechanisms specifically designed to handle asynchronous data.</li>
                    <li>Applying the developed models to real-world astronomical datasets to assess their practical capabilities.</li>

                    </ul>
                    <p>[1] ASTROMER-A transformer-based embedding for the representation of light curves. <em>Astronomy &amp; Astrophysics</em> </p>
                    <p><a href='https://www.aanda.org/articles/aa/pdf/2023/02/aa43928-22.pdf'><em>https://www.aanda.org/articles/aa/pdf/2023/02/aa43928-22.pdf</em></a></p>
                    <p>[2] Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., … Polosukhin, I. (2021). Attention is all you need. arxiv:1706.03762: <a href='https://arxiv.org/abs/1706.03762' target='_blank' class='url'>https://arxiv.org/abs/1706.03762</a></p>
                    </div>
                </article>
                <!-- End Blog Card -->

                <!-- Start Blog Card -->
                <article class="card mb-3 mb-sm-5 " id="NNEHT" onclick = "window.location.href='projects/nneht.html'" style="cursor:pointer">
                    <img style="width:100pt"  alt="Image Description " class="card-img-top " src="assets/general/img/home/NNEHT_logo.svg">

                    <div class="card-body " style="cursor:pointer">
                        <a class="d-block small font-weight-bold text-cap mb-2 " href="projects.html#NNETH">NNETH</a>

                        <h3>Computer Vision methods for the Event Horizon Telescope</h3>

                        <p> In 2019, the Event Horizon Telescope Collaboration released the first-ever 
                            image of the M87* 
                            supermassive black hole. Accurate parameterization of images like this 
                            can provide new information 
                            regarding the dynamics of matter close to a black hole. 
                            Moreover, it can enable us to test theories of gravity 
                            and deepen our understanding of the magnetized relativistic 
                            jets created by the blackhole. 
                            In these projects, we deploy deep learning, to parameterize and estimate the 
                            physical parameters of M87*.   </p>

                         
                    </div>
                </article>
                <!-- End Blog Card -->


                <!-- End Blog Card -->
                <article class="card mb-3 mb-sm-5 " id="RCTorch">
                    <img style="width:100pt"  alt="Image Description " class="card-img-top " src="assets/general/img/home/RCTORCH_logo.png">

                    <div class="card-body ">
                        <a class="d-block small font-weight-bold text-cap mb-2 " href="projects.html#RCTorch">RCTorch</a>

                        <h3>Reservoid Computing</h3>

                        <p>Reservoir computers (RCs) are among the fastest to train of all neural networks, 
                            especially when compared to other recurrent neural networks. 
                            RC has this advantage while still handling sequential data exceptionally well. 
                            However, RC adoption has lagged other neural network models because of the model's 
                            sensitivity to its hyper-parameters (HPs).
                            We developed \rctorch, a \pytorch based RC neural network package with automated HP tuning. 
                            In addition, we introduce an unsupervised reservoir computing (RC), capable of discovering 
                            approximate solutions that satisfy ordinary differential equations (ODEs). 
                    </div>
                </article>
                <!-- End Blog Card -->


                <!-- End Blog Card -->
                <article class="card mb-3 mb-sm-5" id="Cosmology">
                    <img style="width:100pt"  alt="Image Description " class="card-img-top " src="assets/general/img/home/COSMO_logo.png">
                    <div class="card-body ">
                        <a class="d-block small font-weight-bold text-cap mb-2" href="projects.html#Cosmology">CINNs</a>

                        <h2 class="h3 ">Cosmologically Informed NNs </h2>

                        <p>The field of machine learning has drawn increasing interest from various fields due to its methods' 
                            success in solving many different problems. An application of these has been to train artificial neural 
                            networks to solve differential equations without needing a numerical solver. In these works, we use 
                            artificial neural networks to represent solutions of the differential equations that govern the 
                            background dynamics of the Universe for four different models. We have applied these methods to various models such as the  &Lambda;CDM, a quintessence model with exponential potential, and the Hu-Sawicki f(R) model. 
                            We used the networks' solutions to perform statistical analyses to estimate the values of 
                            each model's parameters with observational data. Additionally, we use similar methods for holographic 
                            calculation of the bubble wall velocity in a cosmological phase transition, which is crucial to determine 
                            the resulting spectrum of GWs. </p>

                        
                    </div>
                </article>
                <!-- End Blog Card -->

                <!-- End Blog Card -->
                <article class="card mb-3 mb-sm-5" id="ADSML">
                    <img style="width:100pt"  alt="Image Description " class="card-img-top " src="assets/general/img/home/ADSML_logo.png">
                    <div class="card-body ">
                        <a class="d-block small font-weight-bold text-cap mb-2" href="projects.html#ADSML">ADSML</a>

                        <h2 class="h3 ">ADSML</h2>

                        <p>he SAO/NASA Astrophysics Data System (ADS) is a digital library portal for researchers in astronomy and physics, 
                            operated by the Smithsonian Astrophysical Observatory (SAO) under a NASA grant.
                             ADS maintains three bibliographic collections containing more than 15 million records covering 
                             publications in astronomy and astrophysics, physics, and general science, including all arXiv e-prints. 
                             The abstracts and full text of major astronomy and physics publications are indexed and searchable. 
                             At ADS ML, we are applying modern machine learning and natural language processing techniques to 
                             the ADS dataset to train astroBERT, a deeply contextual language model based on research at Google.
                              Using astroBERT, we aim to enrich the ADS dataset and improve its discoverability; in particular, 
                              we are developing our own named entity recognition and concept discovery tools.</p>

                         
                    </div>
                </article>
                <!-- End Blog Card -->

                <!-- End Blog Card -->
                <article class="card mb-3 mb-sm-5 " id="Other">
                    <img style="width:100pt"  alt="Image Description " class="card-img-top " src="assets/general/img/home/OTHER_logo.png">

                    <div class="card-body ">
                        <a class="d-block small font-weight-bold text-cap mb-2 " href="projects.html#Other">Other</a>

                        <h3>Other projects</h3>

                        <p> Besides the projects described above, we have engaged in various other projects in particularly in astronomy and physics. 
                            Work on StellarNet , eigenvalue problems, embedding on galaxy images using auto-encoders and other topics are described 
                            in the page link provided. </p>

                        
                    </div>
                </article>
                <!-- End Blog Card -->


                <div class="space-bottom-2"></div>

            </div>
        </div>
        <!-- End Blog Listing Section -->
    </main>
    <!-- ========== END MAIN ========== -->

    <!-- ========== FOOTER ========== -->
    <footer-component></footer-component>
    <!-- ========== END FOOTER ========== -->


    <!-- JS Global Compulsory  -->
    <script src="assets/front_v3_3/vendor/jquery/dist/jquery.min.js "></script>
    <script src="assets/front_v3_3/vendor/jquery-migrate/dist/jquery-migrate.min.js"></script>
    <script src="assets/front_v3_3/vendor/bootstrap/dist/js/bootstrap.bundle.min.js "></script>

    <!-- JS Implementing Plugins -->
    <script src="assets/front_v3_3/vendor/hs-header/dist/hs-header.min.js"></script>
    <script src="assets/front_v3_3/vendor/hs-go-to/dist/hs-go-to.min.js "></script>
    <script src="assets/front_v3_3/vendor/hs-unfold/dist/hs-unfold.min.js"></script>
    <script src="assets/front_v3_3/vendor/hs-mega-menu/dist/hs-mega-menu.min.js "></script>
    <script src="assets/front_v3_3/vendor/hs-show-animation/dist/hs-show-animation.min.js"></script>
    <script src="assets/front_v3_3/vendor/jquery-validation/dist/jquery.validate.min.js "></script>

    <!-- JS Front -->
    <script src="assets/front_v3_3/js/theme.min.js"></script>

    <!-- IE Support -->
    <script>
        if (/MSIE \d|Trident.*rv:/.test(navigator.userAgent)) document.write('<script src="assets/front_v3_3/vendor/babel-polyfill/dist/polyfill.js"><\/script>');
    </script>

    <!-- JS -->
    <script src="assets/common_components/js/header.js"></script>
    <script src="assets/common_components/js/footer.js"></script>
</body>

</html>